---
title: "Research"
date-modified: 2025-08-30
---

## Why Trust Science? {#overview}
We make billion-dollar decisions based on climate models, even though every model is flawed, strictly speaking. My research asks: *what does it mean to trust science when its tools are limited?* More specifically, how do climate scientists use computer models to generate knowledge? Why are their models "wrong but useful"?

By focusing on robustness, error, and how we explain modeling results, I show why imperfect models can still yield trustworthy insights. My work shows how philosophy can help make sense of scientific uncertainty and strengthen trust in climate research. 

## Bridging Science and Philosophy {#bridging-science}
Both philosophers and scientists care about knowledge—what it is, how we get it, and whether we can trust it. My work brings these communities into dialogue by asking how the credibility of knowledge is established and shared.

I have published in both leading philosophy journals and interdisciplinary science venues, including *Synthese*, *Climatic Change*, and *Geoscientific Model Development*. In these publications I introduce philosophical tools—such as robustness reasoning and the analysis of error—to scientific audiences, helping them reflect on how models generate and justify knowledge. I also present regularly at conferences and workshops that bring philosophers and scientists together, where my work has influenced how climate researchers discuss uncertainty and how philosophers ground their theories in real modeling practice.

In addition to publications and conference work, I collaborate directly with climate scientists at NASA Goddard Institute of Space Studies, the National Center for Atmospheric Research, Cornell University, and Indiana University. These collaborations have refined how scientists evaluate their models, encouraged open discussions about the limits of prediction, and given philosophers concrete insights into modeling practices. Together, these activities show how philosophy can clarify scientific debates and how scientific practice can enrich philosophical theory.

## Research Agenda {#research-agenda}
1. **Uncertainty and Representation** – How do climate models represent uncertainty, and what kinds of knowledge do they provide about the future?

2. **Robustness and Trustworthiness** – What makes scientific results robust, and how should robustness guide research agendas?

3.  **Error, Failure, and Pluralism** – Why should we value disagreement and low-skill models in science, and how can they advance collective knowledge?

4. **AI and Climate Modeling** – How can philosophy shape debates about explainable AI in climate science and beyond?

## Selected Publications {#selected-publications}
- O’Loughlin, R., Li, D., Neale, R., & O’Brien, T.A. (2025). Moving beyond post hoc explainable artificial intelligence: lessons from dynamical climate modeling. Geoscientific Model Development, 18, 787–802. [link](https://doi.org/10.5194/gmd-18-787-2025)

- O’Loughlin, R. (2024). Why we need lower-performance climate models. Climatic Change, 177(2), 1–21. link

- O’Loughlin, R. (2023). Diagnosing errors in climate model intercomparisons. European Journal for Philosophy of Science, 13(2), 1–29. link

- O’Loughlin, R. & Li, D. (2022). Model robustness in economics: the admissibility and evaluation of tractability assumptions. Synthese, 200, 1–23. link

- O’Loughlin, R. (2021). Robustness reasoning in climate model comparisons. Studies in History and Philosophy of Science: Part A, 85, 35–43. link

[Full list in CV →](about.qmd)

## Current Projects {#works-in-progress}
#### Does Model Weighting Reduce Uncertainty? A Bayesian Clarification

Climate scientists often weight climate models that best fit past data, claiming this reduces uncertainty in projections. My current work shows that if weighting is understood as Bayesian updating, this interpretation is misleading: normalization narrows ensemble spread but does not increase epistemic confidence. This project clarifies when weighting genuinely improves knowledge and when it risks creating an illusion of certainty—an issue with direct implications for scientific communication and policy.

*Updated: {{< meta date-modified >}}*
